{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "627f7fe197c14ad188403da382381628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e699a6bb4e2943a9bb3dbae1d8e0ffc5",
              "IPY_MODEL_5ae111a04d0d4f28b5d6a94499bafecc",
              "IPY_MODEL_a48af2fcb60b4763b908c7e110e32bd1"
            ],
            "layout": "IPY_MODEL_39406095869141299a45c84b0b6f0751"
          }
        },
        "e699a6bb4e2943a9bb3dbae1d8e0ffc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4d23015fd894ecb8aecc029d8dea201",
            "placeholder": "​",
            "style": "IPY_MODEL_48334f93512f4058b8a717e795dd07ba",
            "value": " 28%"
          }
        },
        "5ae111a04d0d4f28b5d6a94499bafecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed4cd8eb9b514c9cbb0ac7b538ea27c7",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8aaaaff8a7ee42258882ccb61e1fa4b3",
            "value": 7
          }
        },
        "a48af2fcb60b4763b908c7e110e32bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_435945736f054ecb9d801a0cff13683c",
            "placeholder": "​",
            "style": "IPY_MODEL_541f7e16821f42768273f5c4bc7122aa",
            "value": " 7/25 [07:03&lt;16:35, 55.28s/it]"
          }
        },
        "39406095869141299a45c84b0b6f0751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d23015fd894ecb8aecc029d8dea201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48334f93512f4058b8a717e795dd07ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed4cd8eb9b514c9cbb0ac7b538ea27c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aaaaff8a7ee42258882ccb61e1fa4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "435945736f054ecb9d801a0cff13683c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541f7e16821f42768273f5c4bc7122aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is34cEfk3qZp",
        "outputId": "b7ee4d2a-a04b-4cf9-af0f-30c61babb53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNbANSJtROkB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.25),\n",
        "    transforms.RandomVerticalFlip(p=0.25),\n",
        "    transforms.RandomRotation(degrees=(0, 180)),\n",
        "    ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "c_nQRvI9fcVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "train_data = torchvision.datasets.CIFAR10(\n",
        "    root='CIFAR10/train',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    #transform=train_transform\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='CIFAR10/test',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO-AL040RRnx",
        "outputId": "1028aab2-3781-4bc3-9101-de2e26a2cca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhPKiS04Rsi4",
        "outputId": "77a58618-2208-4f93-d83e-fda82ac64a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset CIFAR10\n",
              "     Number of datapoints: 50000\n",
              "     Root location: CIFAR10/train\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset CIFAR10\n",
              "     Number of datapoints: 10000\n",
              "     Root location: CIFAR10/test\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes, len(train_data.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5taWWDMRoog",
        "outputId": "2707586d-2d95-4775-e1d1-dfdfcf5ce768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['airplane',\n",
              "  'automobile',\n",
              "  'bird',\n",
              "  'cat',\n",
              "  'deer',\n",
              "  'dog',\n",
              "  'frog',\n",
              "  'horse',\n",
              "  'ship',\n",
              "  'truck'],\n",
              " 10)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "\n",
        "image = image.permute(1, 2, 0)\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "Yb8ZOEKJRqBw",
        "outputId": "1eb28b38-eb38-4ffa-87aa-a70302cc99ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "train_loader, test_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9d367prRwlw",
        "outputId": "28f0a8f8-656c-4dff-eebe-d2ef81c62a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7c183c6ced70>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7c183c9fbeb0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sdu5bNUhOu-",
        "outputId": "f62710fc-03b0-4003-853c-f268954a1409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(782, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "metadata": {
        "id": "PK6jQ9dyR0H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_data.shape, example_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7UVdtFyR3Y5",
        "outputId": "986e1504-a9fd-4eb2-dcf3-52cdf812e9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 3, 32, 32]), torch.Size([64]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION 1\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5), # 10 x 28 x 28\n",
        "            nn.MaxPool2d(kernel_size=2), # 10 x 14 x 14\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3), # 10 x 12 x 12\n",
        "            nn.MaxPool2d(kernel_size=2), # 10 x 6 x 6\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 10 x 6 x 6 = 360\n",
        "            nn.Linear(in_features=360, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "eAiDHIt8R5Hn",
        "outputId": "0a673c42-e1ef-413b-dfef-9803767a7c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=5), # 10 x 28 x 28\\n            nn.MaxPool2d(kernel_size=2), # 10 x 14 x 14\\n            nn.ReLU()\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3), # 10 x 12 x 12\\n            nn.MaxPool2d(kernel_size=2), # 10 x 6 x 6\\n            nn.ReLU()\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 10 x 6 x 6 = 360\\n            nn.Linear(in_features=360, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION 2\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3), # 10 x 30 x 30\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=3), # 16 x 28 x 28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 16 x 14 x 14\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=3), # 10 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 10 x 6 x 6\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 10 x 6 x 6 = 360\n",
        "            nn.Linear(in_features=360, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "pzZR3ECVVbBY",
        "outputId": "c94bb3a7-9cfd-4720-8d93-2de0ccede659"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3), # 10 x 30 x 30\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=3), # 16 x 28 x 28\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 16 x 14 x 14\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=3), # 10 x 12 x 12\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 10 x 6 x 6\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 10 x 6 x 6 = 360\\n            nn.Linear(in_features=360, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION 3\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=28, kernel_size=5, padding=2), # 28 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 28 x 16 x 16\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=28, out_channels=28, kernel_size=3), # 28 x 14 x 14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=28, out_channels=28, kernel_size=3), # 28 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 28 x 6 x 6\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 28 x 6 x 6\n",
        "            nn.Linear(in_features=28*6*6, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "lgOKeYVlYk_P",
        "outputId": "38ae0a5a-68e7-4ff9-c759-885d1461c409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=16, out_channels=28, kernel_size=5, padding=2), # 28 x 32 x 32\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 28 x 16 x 16\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=28, out_channels=28, kernel_size=3), # 28 x 14 x 14\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=28, out_channels=28, kernel_size=3), # 28 x 12 x 12\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 28 x 6 x 6\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 28 x 6 x 6\\n            nn.Linear(in_features=28*6*6, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION 4\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 32 x 16 x 16\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 14 x 14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3), # 64 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 6 x 6\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 64 x 6 x 6\n",
        "            nn.Linear(in_features=64*6*6, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "rXrc4oh5m2ne",
        "outputId": "3f1e2e45-c8a3-4f47-d0d1-1657223da254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 32 x 16 x 16\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 14 x 14\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3), # 64 x 12 x 12\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 64 x 6 x 6\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 64 x 6 x 6\\n            nn.Linear(in_features=64*6*6, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VERSION 5\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3), # 16 x 30 x 30\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3), # 32 x 28 x 28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 32 x 14 x 14\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3), # 64 x 10 x 10\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 5 x 5\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 64 x 5 x 5\n",
        "            nn.Linear(in_features=64*5*5, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2UEJRc-73bZ9",
        "outputId": "c9acf520-c9c4-47d8-867e-e7d8fc9ee248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3), # 16 x 30 x 30\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3), # 32 x 28 x 28\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 32 x 14 x 14\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 12 x 12\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3), # 64 x 10 x 10\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 64 x 5 x 5\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 64 x 5 x 5\\n            nn.Linear(in_features=64*5*5, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 6:\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 32 x 16 x 16\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 14 x 14\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3), # 128 x 12 x 12\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 128 x 6 x 6\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 128 x 6 x 6\n",
        "            nn.Linear(in_features=128*6*6, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "O33dntZm8NlN",
        "outputId": "2dc5e8e5-5ffd-4e2d-c48d-a4b387d00150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, padding=2), # 16 x 32 x 32\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 32 x 16 x 16\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # 64 x 14 x 14\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3), # 128 x 12 x 12\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 128 x 6 x 6\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 128 x 6 x 6\\n            nn.Linear(in_features=128*6*6, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 7: Overfitting\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 8 x 8\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 256 x 4 x 4\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 256 x 4 x 4\n",
        "            nn.Linear(in_features=256*4*4, out_features=1024),\n",
        "            nn.ReLU(),\n",
        "            #nn.Linear(in_features=1024, out_features=256),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "F6NuvabNKo7N",
        "outputId": "9ff76f4f-606e-4e02-a3a9-2261b1ab85a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\\n            nn.ReLU(),\\n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 8 x 8\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 256 x 4 x 4\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 256 x 4 x 4\\n            nn.Linear(in_features=256*4*4, out_features=1024),\\n            nn.ReLU(),\\n            #nn.Linear(in_features=1024, out_features=256),\\n            #nn.ReLU(),\\n            nn.Linear(in_features=1024, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 8\n",
        "\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 128 x 4 x 4\n",
        "            #nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 4 x 4\n",
        "            #nn.ReLU(),\n",
        "            #nn.MaxPool2d(kernel_size=2) # 256 x 2 x 2\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 128 x 4 x 4\n",
        "            nn.Linear(in_features=128*4*4, out_features=1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ynScgUNmULb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "2d59c11a-f07d-4916-fd77-16c10375f469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2), # 128 x 4 x 4\\n            #nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 4 x 4\\n            #nn.ReLU(),\\n            #nn.MaxPool2d(kernel_size=2) # 256 x 2 x 2\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 128 x 4 x 4\\n            nn.Linear(in_features=128*4*4, out_features=1024),\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.Linear(in_features=1024, out_features=1024),\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.Linear(in_features=1024, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 9\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 128 x 4 x 4\n",
        "            #nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 4 x 4\n",
        "            #nn.Dropout(0.35),\n",
        "            #nn.BatchNorm2d(256),\n",
        "            #nn.ReLU(),\n",
        "            #nn.MaxPool2d(kernel_size=2) # 256 x 2 x 2\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 128 x 4 x 4\n",
        "            nn.Linear(in_features=128*4*4, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "5Og_O4cUxl02",
        "outputId": "e60d7a59-9563-4165-9fcc-0a73941aeb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CNN(nn.Module):\\n    def __init__(self):\\n        super().__init__() # 3 x 32 x 32\\n        self.block_1 = nn.Sequential(\\n            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2), # 32 x 32 x 32\\n            nn.Dropout(0.35),\\n            nn.BatchNorm2d(32),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\\n            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2), # 64 x 16 x 16\\n            nn.Dropout(0.35),\\n            nn.BatchNorm2d(64),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\\n        )\\n        self.block_2 = nn.Sequential(\\n            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2), # 128 x 8 x 8\\n            nn.Dropout(0.35),\\n            nn.BatchNorm2d(128),\\n            nn.ReLU(),\\n            nn.MaxPool2d(kernel_size=2), # 128 x 4 x 4\\n            #nn.Conv2d(in_channels=128, out_channels=256, kernel_size=5, padding=2), # 256 x 4 x 4\\n            #nn.Dropout(0.35),\\n            #nn.BatchNorm2d(256),\\n            #nn.ReLU(),\\n            #nn.MaxPool2d(kernel_size=2) # 256 x 2 x 2\\n        )\\n        self.classifier = nn.Sequential(\\n            nn.Flatten(), # 128 x 4 x 4\\n            nn.Linear(in_features=128*4*4, out_features=1024),\\n            #nn.BatchNorm1d(1024),\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.Linear(in_features=1024, out_features=1024),\\n            #nn.BatchNorm1d(1024),\\n            nn.Dropout(0.35),\\n            nn.ReLU(),\\n            nn.Linear(in_features=1024, out_features=10)\\n        )\\n\\n    def forward(self, x: torch.Tensor):\\n        x = self.block_1(x)\\n        x = self.block_2(x)\\n        x = self.classifier(x)\\n        return x\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 10: VGG\n",
        "\"\"\"\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1), # 32 x 32 x 32\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1), # 32 x 32 x 32\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # 64 x 16 x 16\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # 64 x 16 x 16\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\n",
        "        )\n",
        "        self.block_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # 128 x 8 x 8\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1), # 128 x 8 x 8\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 128 x 4 x 4\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 128 x 4 x 4\n",
        "            nn.Linear(in_features=128*4*4, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            #nn.Dropout(0.35),\n",
        "            #nn.ReLU(),\n",
        "            #nn.Linear(in_features=1024, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        x = self.block_3(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4bl2TYM1hcqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 11:\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 3 x 32 x 32\n",
        "        self.block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1), # 32 x 32 x 32\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1), # 32 x 32 x 32\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 32 x 16 x 16\n",
        "        )\n",
        "        self.block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1), # 64 x 16 x 16\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # 64 x 16 x 16\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # 64 x 8 x 8\n",
        "        )\n",
        "        self.block_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3, padding=1), # 96 x 8 x 8\n",
        "            nn.Conv2d(in_channels=96, out_channels=96, kernel_size=3, padding=1), # 96 x 8 x 8\n",
        "            nn.Dropout(0.35),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2), # 96 x 4 x 4\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(), # 64 x 8 x 8\n",
        "            nn.Linear(in_features=64*8*8, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            #nn.Dropout(0.35),\n",
        "            #nn.ReLU(),\n",
        "            #nn.Linear(in_features=1024, out_features=1024),\n",
        "            #nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(0.35),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=1024, out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.block_1(x)\n",
        "        x = self.block_2(x)\n",
        "        #x = self.block_3(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lhmmyLZpzav-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "network = CNN()\n",
        "network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq9akCOESMeY",
        "outputId": "01493192-52fd-4637-d42c-9bfa07f75f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (block_1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Dropout(p=0.35, inplace=False)\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Dropout(p=0.35, inplace=False)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (block_3): Sequential(\n",
              "    (0): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): Dropout(p=0.35, inplace=False)\n",
              "    (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (2): Dropout(p=0.35, inplace=False)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=1024, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  # Note: you need the \"raw\" GitHub URL for this to work\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi_l4wN6SQUB",
        "outputId": "432937d0-b110-40e1-c8a8-1f22e5c35687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "helper_functions.py already exists, skipping download\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=network.parameters(),\n",
        "                            lr=0.001,\n",
        "                            momentum=0.9,\n",
        "                            weight_decay=0.005)\n",
        "\n",
        "from helper_functions import accuracy_fn"
      ],
      "metadata": {
        "id": "Ta1Ld0m_SHjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              accuracy_fn):\n",
        "\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for batch, (X, y) in enumerate(data_loader):\n",
        "        # 1. forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. cal loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy_fn(y_true=y,\n",
        "                                 y_pred=y_pred.argmax(dim=1))\n",
        "\n",
        "        # 3. optimizer 0 grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. loss back\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            train_loss_batch = train_loss / (batch + 1)\n",
        "            train_acc_batch = train_acc / (batch + 1)\n",
        "            print(f\"Train batch: {batch + 1} | Train loss: {train_loss_batch:.5f} | Train acc: {train_acc_batch:.5f}\")\n",
        "\n",
        "    train_loss /= len(data_loader)\n",
        "    train_acc /= len(data_loader)\n",
        "\n",
        "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.5f}\")"
      ],
      "metadata": {
        "id": "Fdc5F39dSVnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "             data_loader: torch.utils.data.DataLoader,\n",
        "             loss_fn: torch.nn.Module,\n",
        "             accuracy_fn):\n",
        "\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(data_loader):\n",
        "            test_pred = model(X)\n",
        "\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "            test_acc += accuracy_fn(y_true=y,\n",
        "                                    y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "            if batch % 1000 == 0:\n",
        "                test_loss_batch = test_loss / (batch + 1)\n",
        "                test_acc_batch = test_acc / (batch + 1)\n",
        "                print(f\"Test batch: {batch + 1} | Test loss: {test_loss_batch:.5f} | Test acc: {test_acc_batch:.5f}\")\n",
        "\n",
        "        test_loss /= len(data_loader)\n",
        "        test_acc /= len(data_loader)\n",
        "        print(f\"Test loss: {test_loss:.5f} | Test acc: {test_acc:.5f}\\n\")"
      ],
      "metadata": {
        "id": "9o5oK6WdScEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "epochs = 25\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    train_step(model=network,\n",
        "              data_loader=train_loader,\n",
        "              loss_fn=loss_fn,\n",
        "              optimizer=optimizer,\n",
        "              accuracy_fn=accuracy_fn)\n",
        "\n",
        "    test_step(model=network,\n",
        "             data_loader=test_loader,\n",
        "             loss_fn=loss_fn,\n",
        "             accuracy_fn=accuracy_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "627f7fe197c14ad188403da382381628",
            "e699a6bb4e2943a9bb3dbae1d8e0ffc5",
            "5ae111a04d0d4f28b5d6a94499bafecc",
            "a48af2fcb60b4763b908c7e110e32bd1",
            "39406095869141299a45c84b0b6f0751",
            "e4d23015fd894ecb8aecc029d8dea201",
            "48334f93512f4058b8a717e795dd07ba",
            "ed4cd8eb9b514c9cbb0ac7b538ea27c7",
            "8aaaaff8a7ee42258882ccb61e1fa4b3",
            "435945736f054ecb9d801a0cff13683c",
            "541f7e16821f42768273f5c4bc7122aa"
          ]
        },
        "id": "Q19D3tnHSeHM",
        "outputId": "b9ef3fc5-60e7-42b4-9b60-de888c329196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "627f7fe197c14ad188403da382381628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Train batch: 1 | Train loss: 2.31102 | Train acc: 17.18750\n",
            "Train batch: 101 | Train loss: 2.05301 | Train acc: 25.21658\n",
            "Train batch: 201 | Train loss: 1.88757 | Train acc: 31.65423\n",
            "Train batch: 301 | Train loss: 1.79194 | Train acc: 34.97197\n",
            "Train batch: 401 | Train loss: 1.72649 | Train acc: 37.34024\n",
            "Train batch: 501 | Train loss: 1.67454 | Train acc: 39.35566\n",
            "Train batch: 601 | Train loss: 1.63118 | Train acc: 40.81999\n",
            "Train batch: 701 | Train loss: 1.59363 | Train acc: 42.43046\n",
            "Train loss: 1.56363 | Train acc: 43.51822\n",
            "Test batch: 1 | Test loss: 1.37498 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 1.59166 | Test acc: 50.64935\n",
            "Test batch: 2001 | Test loss: 1.59009 | Test acc: 50.72464\n",
            "Test batch: 3001 | Test loss: 1.59075 | Test acc: 51.08297\n",
            "Test batch: 4001 | Test loss: 1.58624 | Test acc: 51.28718\n",
            "Test batch: 5001 | Test loss: 1.57930 | Test acc: 51.94961\n",
            "Test batch: 6001 | Test loss: 1.58487 | Test acc: 51.45809\n",
            "Test batch: 7001 | Test loss: 1.59078 | Test acc: 51.14984\n",
            "Test batch: 8001 | Test loss: 1.58904 | Test acc: 51.05612\n",
            "Test batch: 9001 | Test loss: 1.59194 | Test acc: 50.91656\n",
            "Test loss: 1.59118 | Test acc: 50.88000\n",
            "\n",
            "Epoch: 1\n",
            "Train batch: 1 | Train loss: 1.54245 | Train acc: 54.68750\n",
            "Train batch: 101 | Train loss: 1.33728 | Train acc: 52.70730\n",
            "Train batch: 201 | Train loss: 1.31022 | Train acc: 53.98010\n",
            "Train batch: 301 | Train loss: 1.28092 | Train acc: 54.79132\n",
            "Train batch: 401 | Train loss: 1.25401 | Train acc: 55.58759\n",
            "Train batch: 501 | Train loss: 1.23491 | Train acc: 56.28743\n",
            "Train batch: 601 | Train loss: 1.21650 | Train acc: 56.98575\n",
            "Train batch: 701 | Train loss: 1.19823 | Train acc: 57.67876\n",
            "Train loss: 1.18313 | Train acc: 58.24608\n",
            "Test batch: 1 | Test loss: 0.67173 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 1.03658 | Test acc: 63.03696\n",
            "Test batch: 2001 | Test loss: 1.03933 | Test acc: 63.16842\n",
            "Test batch: 3001 | Test loss: 1.04449 | Test acc: 63.07897\n",
            "Test batch: 4001 | Test loss: 1.04107 | Test acc: 63.38415\n",
            "Test batch: 5001 | Test loss: 1.03376 | Test acc: 64.10718\n",
            "Test batch: 6001 | Test loss: 1.04086 | Test acc: 63.88935\n",
            "Test batch: 7001 | Test loss: 1.04535 | Test acc: 63.56235\n",
            "Test batch: 8001 | Test loss: 1.03977 | Test acc: 63.56705\n",
            "Test batch: 9001 | Test loss: 1.04347 | Test acc: 63.48184\n",
            "Test loss: 1.04569 | Test acc: 63.25000\n",
            "\n",
            "Epoch: 2\n",
            "Train batch: 1 | Train loss: 0.98055 | Train acc: 67.18750\n",
            "Train batch: 101 | Train loss: 1.01701 | Train acc: 64.37191\n",
            "Train batch: 201 | Train loss: 1.00132 | Train acc: 65.01866\n",
            "Train batch: 301 | Train loss: 1.00233 | Train acc: 65.00208\n",
            "Train batch: 401 | Train loss: 0.99600 | Train acc: 65.12235\n",
            "Train batch: 501 | Train loss: 0.98291 | Train acc: 65.57822\n",
            "Train batch: 601 | Train loss: 0.97521 | Train acc: 65.87198\n",
            "Train batch: 701 | Train loss: 0.96779 | Train acc: 66.20007\n",
            "Train loss: 0.96069 | Train acc: 66.44421\n",
            "Test batch: 1 | Test loss: 0.49307 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 0.93972 | Test acc: 66.13387\n",
            "Test batch: 2001 | Test loss: 0.93603 | Test acc: 66.91654\n",
            "Test batch: 3001 | Test loss: 0.94928 | Test acc: 67.24425\n",
            "Test batch: 4001 | Test loss: 0.95223 | Test acc: 66.95826\n",
            "Test batch: 5001 | Test loss: 0.94752 | Test acc: 67.20656\n",
            "Test batch: 6001 | Test loss: 0.95229 | Test acc: 66.77220\n",
            "Test batch: 7001 | Test loss: 0.96174 | Test acc: 66.51907\n",
            "Test batch: 8001 | Test loss: 0.95623 | Test acc: 66.71666\n",
            "Test batch: 9001 | Test loss: 0.96370 | Test acc: 66.57038\n",
            "Test loss: 0.96672 | Test acc: 66.47000\n",
            "\n",
            "Epoch: 3\n",
            "Train batch: 1 | Train loss: 0.71413 | Train acc: 78.12500\n",
            "Train batch: 101 | Train loss: 0.82874 | Train acc: 70.91584\n",
            "Train batch: 201 | Train loss: 0.83094 | Train acc: 70.93439\n",
            "Train batch: 301 | Train loss: 0.83386 | Train acc: 70.82122\n",
            "Train batch: 401 | Train loss: 0.82984 | Train acc: 70.97880\n",
            "Train batch: 501 | Train loss: 0.82728 | Train acc: 70.93001\n",
            "Train batch: 601 | Train loss: 0.82310 | Train acc: 71.10025\n",
            "Train batch: 701 | Train loss: 0.81710 | Train acc: 71.37571\n",
            "Train loss: 0.81384 | Train acc: 71.51135\n",
            "Test batch: 1 | Test loss: 0.49630 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 0.79077 | Test acc: 72.62737\n",
            "Test batch: 2001 | Test loss: 0.81503 | Test acc: 71.81409\n",
            "Test batch: 3001 | Test loss: 0.83455 | Test acc: 71.37621\n",
            "Test batch: 4001 | Test loss: 0.83838 | Test acc: 71.03224\n",
            "Test batch: 5001 | Test loss: 0.83567 | Test acc: 71.46571\n",
            "Test batch: 6001 | Test loss: 0.84100 | Test acc: 70.90485\n",
            "Test batch: 7001 | Test loss: 0.84451 | Test acc: 70.76132\n",
            "Test batch: 8001 | Test loss: 0.83988 | Test acc: 70.89114\n",
            "Test batch: 9001 | Test loss: 0.84337 | Test acc: 70.79213\n",
            "Test loss: 0.84585 | Test acc: 70.80000\n",
            "\n",
            "Epoch: 4\n",
            "Train batch: 1 | Train loss: 0.59992 | Train acc: 81.25000\n",
            "Train batch: 101 | Train loss: 0.71610 | Train acc: 75.66522\n",
            "Train batch: 201 | Train loss: 0.71177 | Train acc: 75.57525\n",
            "Train batch: 301 | Train loss: 0.70973 | Train acc: 75.48277\n",
            "Train batch: 401 | Train loss: 0.70390 | Train acc: 75.74423\n",
            "Train batch: 501 | Train loss: 0.70501 | Train acc: 75.66118\n",
            "Train batch: 601 | Train loss: 0.70475 | Train acc: 75.72535\n",
            "Train batch: 701 | Train loss: 0.70146 | Train acc: 75.84700\n",
            "Train loss: 0.70172 | Train acc: 75.80523\n",
            "Test batch: 1 | Test loss: 1.08624 | Test acc: 0.00000\n",
            "Test batch: 1001 | Test loss: 0.74169 | Test acc: 73.92607\n",
            "Test batch: 2001 | Test loss: 0.75687 | Test acc: 74.01299\n",
            "Test batch: 3001 | Test loss: 0.77520 | Test acc: 73.27557\n",
            "Test batch: 4001 | Test loss: 0.78128 | Test acc: 72.53187\n",
            "Test batch: 5001 | Test loss: 0.78249 | Test acc: 72.64547\n",
            "Test batch: 6001 | Test loss: 0.78595 | Test acc: 72.55457\n",
            "Test batch: 7001 | Test loss: 0.79154 | Test acc: 72.24682\n",
            "Test batch: 8001 | Test loss: 0.78602 | Test acc: 72.35346\n",
            "Test batch: 9001 | Test loss: 0.78927 | Test acc: 72.38085\n",
            "Test loss: 0.78807 | Test acc: 72.50000\n",
            "\n",
            "Epoch: 5\n",
            "Train batch: 1 | Train loss: 0.65885 | Train acc: 76.56250\n",
            "Train batch: 101 | Train loss: 0.58668 | Train acc: 79.90408\n",
            "Train batch: 201 | Train loss: 0.59573 | Train acc: 79.57090\n",
            "Train batch: 301 | Train loss: 0.59525 | Train acc: 79.46429\n",
            "Train batch: 401 | Train loss: 0.59592 | Train acc: 79.51216\n",
            "Train batch: 501 | Train loss: 0.59562 | Train acc: 79.36003\n",
            "Train batch: 601 | Train loss: 0.59345 | Train acc: 79.42232\n",
            "Train batch: 701 | Train loss: 0.59174 | Train acc: 79.45123\n",
            "Train loss: 0.59172 | Train acc: 79.47970\n",
            "Test batch: 1 | Test loss: 0.34491 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 0.71011 | Test acc: 75.72428\n",
            "Test batch: 2001 | Test loss: 0.75317 | Test acc: 74.31284\n",
            "Test batch: 3001 | Test loss: 0.77409 | Test acc: 73.97534\n",
            "Test batch: 4001 | Test loss: 0.78065 | Test acc: 73.55661\n",
            "Test batch: 5001 | Test loss: 0.78092 | Test acc: 73.72525\n",
            "Test batch: 6001 | Test loss: 0.78025 | Test acc: 73.50442\n",
            "Test batch: 7001 | Test loss: 0.77762 | Test acc: 73.48950\n",
            "Test batch: 8001 | Test loss: 0.77298 | Test acc: 73.56580\n",
            "Test batch: 9001 | Test loss: 0.77299 | Test acc: 73.58071\n",
            "Test loss: 0.77439 | Test acc: 73.55000\n",
            "\n",
            "Epoch: 6\n",
            "Train batch: 1 | Train loss: 0.51017 | Train acc: 82.81250\n",
            "Train batch: 101 | Train loss: 0.45168 | Train acc: 84.77723\n",
            "Train batch: 201 | Train loss: 0.46007 | Train acc: 84.33613\n",
            "Train batch: 301 | Train loss: 0.46782 | Train acc: 83.96491\n",
            "Train batch: 401 | Train loss: 0.47144 | Train acc: 83.96587\n",
            "Train batch: 501 | Train loss: 0.48364 | Train acc: 83.40506\n",
            "Train batch: 601 | Train loss: 0.48382 | Train acc: 83.41826\n",
            "Train batch: 701 | Train loss: 0.48370 | Train acc: 83.39649\n",
            "Train loss: 0.48596 | Train acc: 83.23609\n",
            "Test batch: 1 | Test loss: 0.18391 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 0.74184 | Test acc: 75.02498\n",
            "Test batch: 2001 | Test loss: 0.75667 | Test acc: 75.06247\n",
            "Test batch: 3001 | Test loss: 0.78206 | Test acc: 74.44185\n",
            "Test batch: 4001 | Test loss: 0.77840 | Test acc: 74.38140\n",
            "Test batch: 5001 | Test loss: 0.77910 | Test acc: 74.46511\n",
            "Test batch: 6001 | Test loss: 0.77701 | Test acc: 74.45426\n",
            "Test batch: 7001 | Test loss: 0.77674 | Test acc: 74.36081\n",
            "Test batch: 8001 | Test loss: 0.77349 | Test acc: 74.50319\n",
            "Test batch: 9001 | Test loss: 0.77424 | Test acc: 74.34729\n",
            "Test loss: 0.77494 | Test acc: 74.26000\n",
            "\n",
            "Epoch: 7\n",
            "Train batch: 1 | Train loss: 0.43764 | Train acc: 84.37500\n",
            "Train batch: 101 | Train loss: 0.38653 | Train acc: 87.50000\n",
            "Train batch: 201 | Train loss: 0.37230 | Train acc: 87.97419\n",
            "Train batch: 301 | Train loss: 0.37622 | Train acc: 87.64016\n",
            "Train batch: 401 | Train loss: 0.37800 | Train acc: 87.54286\n",
            "Train batch: 501 | Train loss: 0.38071 | Train acc: 87.37837\n",
            "Train batch: 601 | Train loss: 0.38283 | Train acc: 87.11002\n",
            "Train batch: 701 | Train loss: 0.38811 | Train acc: 86.86698\n",
            "Train loss: 0.39070 | Train acc: 86.76271\n",
            "Test batch: 1 | Test loss: 0.34147 | Test acc: 100.00000\n",
            "Test batch: 1001 | Test loss: 0.78307 | Test acc: 73.72627\n",
            "Test batch: 2001 | Test loss: 0.84084 | Test acc: 72.86357\n",
            "Test batch: 3001 | Test loss: 0.86173 | Test acc: 72.40920\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-933cd8082ca7>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m               accuracy_fn=accuracy_fn)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     test_step(model=network,\n\u001b[0m\u001b[1;32m     17\u001b[0m              \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m              \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-7e73475e56e1>\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(model, data_loader, loss_fn, accuracy_fn)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_num_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xYjONbD9UvEq"
      }
    }
  ]
}